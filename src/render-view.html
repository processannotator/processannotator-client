<!DOCTYPE html>

<link rel="import" href="a-annotation.html">


<dom-module id="render-view">

	<template>
		<style is="custom-style">


			:host {
				margin: 0;
				width: 100%;
				height: 100%;
			}

			/*#canvas {
				width: 100%;
				height: 100%;
			}*/
			a-scene {
				width: 100%;
				height: 100%;
			}

		</style>
		<span>{{cameraRotation}}</span>
		<a-scene embedded id="canvas">

							<a-entity light="type: directional; color: #FFF; intensity: 0.6" position="-0.5 1 1"></a-entity>

							<a-camera id="camera" camera look-controls wasd-controls user-height="1.6">
								<a-text value$="[[STTResult.transcript]]" side="double"> </a-text>

							 </a-camera>

				<!-- <a-entity raycaster="objects: #fileRepresentation" position="0 0 0.5" rotation="0 180 0"></a-entity> -->
				<!-- <a-text value="Hello. Please move around and take a look." position="0 0 -5"> </a-text> -->





			<!-- <a-obj-model id="fileRepresentation" src$="[[filePath]]"  position="-3 0 -3" on-click="clicked" opacity="1.0"
				animation__mouseenter="startEvents: mouseenter; property: opacity; to:0.5; dur:3000"
				animation__mouseleave="startEvents: mouseleave; property: opacity; to:1.0; dur:3000">
			</a-obj-model> -->

			<a-entity light="type: ambient; color: #BBB"></a-entity>



			<a-entity id="rightVRController" class="vrController" laser-controls="hand: right; interval: 30" raycaster="objects: #fileRepresentation;" on-triggerdown="onTriggerDown" on-triggerup="onTriggerUp" on-raycaster-intersection="onIntersection">





			</a-entity>

			<a-entity id="leftVRController" class="vrController" vive-controls="hand: left; model: false" on-axismove="onAxisMove">

				<!-- <a-entity position$="[[_parsePos(worldIntersectionPoint)]]">


					<a-sphere color="white" radius="0.05"></a-sphere>

				</a-entity> -->




				<!-- The model attribute is added on file change depending on format -->
				<a-entity id="fileRepresentation" material="opacity:0.75; roughness: 0.2; metalness: 0.8" scale$="[[modelScale]] [[modelScale]] [[modelScale]]" on-mouseenter="onMouseEnter" on-mouseleave="onMouseLeave">



					<template id="annotationList" is="dom-repeat" items="[[annotations]]">
						<a-entity position$="[[_parsePos(item.localPosition)]]" opacity="1.0">

							<a-sphere color$="[[item.statusColor]]" radius="0.05" depth="2" animation__created="property: opacity; dur:200; to: 1.0; loop:false;"></a-sphere>


						<a-entity>

							<!-- TODO: Figure out intelligent text positioning algo
									perhaps, as long as there is none, just hide all texts until they are intersected

									Otherwise: Use predefined directions (1,0,0) (0, 1, 0) etc.
									0. divide space into bigger cube volumes
									1. Determine in which part of object we are, eg. top left middle
									2. Is angle between normal of intersected face closer to which dir?
									3. Check if preferred direction for that location is no intersecting with geometry: eg. when left (-x) check if straight line to left is available.
									If not, go for next one. skip middle, check for top direction (+y), which is straight up. If this is available use that direction. Otherwise

									Or perhaps completely different via force directed text nodes
						 -->
							<a-text position$="[[_textPosition(item)]]" scale="1.2 1.2 1.2" look-at$="[[_parsePos(item.localCameraPosition)]]"  transparent="false" side="double" value$="[[item.description]]"></a-text>
						</a-entity>

						</a-entity>

					</template>
				</a-entity>

			</a-entity>




		<a-sky color="gray"></a-sky>
		</a-scene>
		<span>[[filePath]]</span>

	</template>



	<script>
	'use strict' /*eslint global-strict:0*/

	// FIXME: shouldnt those global variables better reside inside the element
	// vis this.glRenderer = ...

	var controls;
	var cssObject;
	var glRenderer;
	var cssRenderer;
	var render;
	var animate;


	Polymer({
		is: "render-view",

		properties: {

			file: {
				type: Object,
				observer: '_fileChanged'
			},
			fileName: {
				type: String
			},
			fileEnding: {
				type: String
			},
			tool: {
				type: 'Object',
				observer: '_toolChanged'
			},
			filePath: {
				type: String,
				notify: true,
				observer: '_filePathChanged',
				value: ''
			},
			annotations: {
				type: Array,
				observer: "_annotationsChanged",
				value: []
			},
			labels: {
				type: Map
			},
			physicalModelState: {
				type: Object,
				observer: "physicalModelStateChanged"
			},
			localIntersectionPoint: {
				type: Object,
				value: new THREE.Vector3(-1000, 0, 0)
			},
			worldIntersectionPoint: {
				type: Object,
				value: new THREE.Vector3(-1000, 0, 0)
			},
			modelScale: {
				type: Number,
				value: 0.5
			},
			STTResult: {
				type: Object,
				value: {transcript: ''}
			}
			// modelScaleString: {
			// 	String,
			// 	computed: "computeVectorString(modelScale)"
			// }
		},

		listeners: {

		},

		_concat: function (...items) {
			console.log(items);
			let result = '';
			for (let item of items) {
				result += item;
			}
			console.log(result);
			return result;
			},
		_parsePos: ({x,y,z}) => {return `${x} ${y} ${z}`;},
		_multiplyPos: (pos, mult) => pos.multiplyScalar(mult),
		_textPosition: function(item) {
			console.log('TEXTPOSITION');
			// console.log(item);
			let dir = new THREE.Vector3().subVectors(item.localCameraPosition, item.localPosition ).normalize().multiplyScalar(0.6);
			return this._parsePos(dir);
			// 	let r = new THREE.Vector3(Math.random(), Math.random(), Math.random());
			// console.log(r);
			// console.warn('HALLLLO\n\n');
			// return `${r.x} ${r.y} ${r.z}`

		},

		ready: function() {
			this.ready = true;
			this.rendering = false;
		},
		attached: function () {
			console.log('ATTACHED');
		},
		clicked: function (evt) {


		},
		onMouseEnter: function (evt) {
		},

		onMouseLeave: function (evt) {
		},

		onIntersection: function (evt) {
			this.worldIntersectionPoint = evt.detail.intersections[0].point.clone();
			let localIntersectionPoint = this.worldIntersectionPoint.clone();
			this.$.fileRepresentation.object3D.worldToLocal(localIntersectionPoint);
			this.localIntersectionPoint = localIntersectionPoint;
		},

		onAxisMove: function (evt) {
			this.trackPadEventCount++;

			// END of touching the pad? reset the saved axis values
			if((evt.detail.axis[0] === 0 && evt.detail.axis[1] === 0)) {
				this.axis = undefined;
				this.trackPadEventCount = 0;
				return;
			}

			// Discard the first few events because if inacuraccies from sensors
			if(this.trackPadEventCount < 3) return;


			if(this.axis === undefined) {
				this.axis = evt.detail.axis;
				return;
			}

			let axis = evt.detail.axis;
			let y = (axis[1] - this.axis[1]) / 10;
			this.modelScale += y;
			this.axis = axis;
		},

		onTriggerDown: function (evt) {
			this.triggerDown = true;
			this.STTResult = {transcript: ''};
		},
		onTriggerUp: function (evt) {
			this.triggerDown = false;

			console.log(this.STTResult);


			let {x, y, z} = this.$.rightVRController.getAttribute('position');
			let localCameraPosition = new THREE.Vector3(x, y, z);
			let worldCameraPosition = localCameraPosition.clone();
			this.$.fileRepresentation.object3D.worldToLocal(localCameraPosition);

			let localPosition = this.localIntersectionPoint.clone();
			let worldPosition = this.worldIntersectionPoint.clone();
			let lookAt = new THREE.Vector3(Math.random(),Math.random(),Math.random());

			this.fire('create-annotation', {
				description: this.STTResult.transcript,
				localCameraPosition: localCameraPosition,
				worldCameraPosition: worldCameraPosition,
				cameraUp: new THREE.Vector3(0,1,0),
				polygon: [localPosition],
				localPosition: localPosition,
				worldPosition: worldPosition
				/* fill out world position */
			});


		},


		physicalModelStateChanged: function () {
			// Not implemented in A-Frame branch cause position/rotation change is handled via one
			// of the vive controllers
		},

		attached: function() {

			this.modus = {modelGrabbing: false};

			fetch('/api/speech-to-text/token')
			.then(response => {return response.text()})
			.then(token => {
				this.STTStream = WatsonSpeech.SpeechToText.recognizeMicrophone({
					token: token,
					interim_results: true,
					realtime: true,
					smart_formatting: true,
					objectMode: true // default false
				});

				// this.STTStream.setEncoding('utf8'); // get text instead of Buffers for on data events
				this.STTStream.on('data', data => {
					// console.log(data);
					if(this.triggerDown) this.STTResult = data.results[0].alternatives[0];

					// console.log(this.STTResult.results[0]);
				});
				this.STTStream.on('error', err => {
					console.log('ERROR\n\n\n');
					console.log(err);
				});
			});

			this.resize();
			this.fire('initialized');
		},


		resize: function(event) {
			let width = this.parentNode.getBoundingClientRect().width;
			let height = this.parentNode.getBoundingClientRect().height;
			// // console.log(width, height);
			// this.style.width = width + 'px';
			// this.style.height = height + 'px';
			// // Make it visually fill the positioned parent
		  this.$.canvas.style.width ='100%';
		  this.$.canvas.style.height='100%';
		  // // ...then set the internal size to match
		  // this.$.canvas.width  = this.$.canvas.offsetWidth;
		  // this.$.canvas.height = this.$.canvas.offsetHeight;


			// // this.$.canvas.style.width = width + 'px';
			// this.$.canvas.style.height = (height - 27) + 'px';

		},
		_filePathChanged: function () {
			console.log('filePath changed!! \n\n');
		},

		_fileChanged: function () {

			this.filePath = URL.createObjectURL(this.file);

			this.$.fileRepresentation.removeAttribute('obj-model');
			this.$.fileRepresentation.removeAttribute('collada-model');
			if(this.fileEnding === 'obj') {
				this.$.fileRepresentation.setAttribute('obj-model', `obj:url(${this.filePath})`);
			} else if (this.fileEnding === 'dae') {
				this.$.fileRepresentation.setAttribute('collada-model', `url(${this.filePath})`);
			} else {
				console.error('Cannot load file with filending', this.fileEnding, '. This should have been catched at file upload.');
			}
		},

		_annotationsChanged: function() {
			// console.log('_annotationsChanged');
		},

		toggleTrack: function(e) {
			//this.modus.modelGrabbing = !this.modus.modelGrabbing;
			// Polymer.dom(this).classList.toggle('track');
		},


		track: function (e) {

		},

		tap: function(e) {

		},

		createPolygon: function (vertices, color) {
			// // IDEA: move to helper object?
			// let polygon = new THREE.Geometry();
			// polygon.vertices = vertices;
			//
			// // calculate faces of preview polygon
			// for (var i = 1; i < polygon.vertices.length - 1; i++) {
			// 	polygon.faces.push( new THREE.Face3( 0, i, i+1 ) )
			// }
			// return new THREE.Mesh(
			// 	polygon,
			// 	new THREE.MeshBasicMaterial( {
			// 		color: color,
			// 		side: THREE.DoubleSide
			// 	} )
			// );
		}

	})
	</script>


</dom-module>
